{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\Program Files\\Java\\jdk1.8.0_271\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"C:\\Installations\\Hadoop\"\n",
    "os.environ[\"SPARK_HOME\"] = \"D:\\spark-2.4.5-bin-hadoop2.7\\spark-2.4.5-bin-hadoop2.7\"\n",
    "\n",
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "    .appName(\"CloudETLProject\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd_test = pd.read_csv('../cleaned_nlp_data/testfinal.csv', sep=',')\n",
    "pd_train = pd.read_csv('../cleaned_nlp_data/trainfinal.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySchema = StructType([ StructField(\"uniqueID\", StringType(), True)\\\n",
    "                       ,StructField(\"drugName\", StringType(), True)\\\n",
    "                       ,StructField(\"condition\", StringType(), True)\\\n",
    "                       ,StructField(\"review\", StringType(), True)\\\n",
    "                       ,StructField(\"rating\", IntegerType(), True)\\\n",
    "                       ,StructField(\"date\", StringType(), True)\\\n",
    "                       ,StructField(\"usefulCount\", StringType(), True)\\\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkConf, SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "df_test = sqlContext.createDataFrame(pd_test, schema=mySchema)\n",
    "df_train = sqlContext.createDataFrame(pd_train, schema=mySchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_df = df_test.drop('uniqueID','drugName','condition', 'date', 'usefulCount' ).collect()\n",
    "drop_df_two = df_train.drop('uniqueID','drugName','condition', 'date', 'usefulCount' ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+------+\n|              review|rating|\n+--------------------+------+\n|gave me rapid hea...|     0|\n|    it cured my mrsa|     1|\n|i have been on zy...|     1|\n|it didnt work as ...|     1|\n|i have had  major...|     1|\n|i had mrsa inf la...|     1|\n|i got a mrsa stap...|     1|\n|very satisfied wi...|     1|\n|effectiveness las...|     0|\n|my psa was going ...|     1|\n|on zytiga for  mo...|     1|\n|began zytiga with...|     1|\n|had tried clariti...|     1|\n|this medicine wor...|     1|\n|i have had cholin...|     1|\n|after travelling ...|     1|\n|i suffered from m...|     1|\n|i recently had te...|     1|\n|it works great fo...|     1|\n|had hives nearly ...|     1|\n+--------------------+------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "test_df = spark.createDataFrame(drop_df)\n",
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+------+\n|              review|rating|\n+--------------------+------+\n|it has no side ef...|     1|\n|my son is halfway...|     1|\n|i used to take an...|     0|\n|this is my first ...|     1|\n|suboxone has comp...|     1|\n|nd day on mg star...|     0|\n|he pulled out but...|     0|\n|abilify changed m...|     1|\n| i ve had  nothin...|     0|\n|i had been on the...|     1|\n|i have been on th...|     1|\n|i have taken anti...|     1|\n|i had crohns with...|     0|\n|have a little bit...|     0|\n|started nexplanon...|     0|\n|i have been takin...|     1|\n|this drug worked ...|     1|\n|ive been taking a...|     1|\n|ive been on every...|     1|\n|i have been on ta...|     1|\n+--------------------+------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "train_df = spark.createDataFrame(drop_df_two)\n",
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trigrams(inputCol=[\"review\",\"rating\"], n=3):\n",
    "    tokenizer = [Tokenizer(inputCol=\"review\", outputCol=\"words\")]\n",
    "\n",
    "# Get rid of stop words\n",
    "    stopremove = [StopWordsRemover(inputCol='words',outputCol='stop_tokens')]\n",
    "\n",
    "# Stem the words\n",
    "\n",
    "# Creates a column for every word, two and three words. n=3\n",
    "    ngrams = [\n",
    "        NGram(n=i, inputCol=\"stop_tokens\", outputCol=\"{0}_grams\".format(i))\n",
    "        for i in range(1, n + 1)\n",
    "    ]\n",
    "# Min term frequency = how many times does it occur in review\n",
    "# df - times drug occurs in document \n",
    "    cv = [\n",
    "        CountVectorizer(vocabSize=2**15,inputCol=\"{0}_grams\".format(i),\n",
    "            outputCol=\"{0}_tf\".format(i))\n",
    "        for i in range(1, n + 1)\n",
    "    ]\n",
    "    idf = [IDF(inputCol=\"{0}_tf\".format(i), outputCol=\"{0}_tfidf\".format(i), minDocFreq=5) for i in range(1, n + 1)]\n",
    "# cv and idf act as a \n",
    "    assembler = [VectorAssembler(\n",
    "        inputCols=[\"{0}_tfidf\".format(i) for i in range(1, n + 1)],\n",
    "        outputCol=\"features\"\n",
    "    )]\n",
    "# stringindexer \n",
    "    label_stringIdx = [StringIndexer(inputCol = \"rating\", outputCol = \"label\")]\n",
    "    # selector = [ChiSqSelector(numTopFeatures=50,featuresCol='rawFeatures', outputCol=\"features\")]\n",
    "    nb = [NaiveBayes(smoothing=1)]\n",
    "    return Pipeline(stages=tokenizer + stopremove + ngrams + cv + idf + assembler + label_stringIdx + nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model \n",
    "trigram_pipelineFit = build_trigrams().fit(train_df)\n",
    "test_results = trigram_pipelineFit.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy Score: 0.8300\nROC-AUC: 0.4123\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator()\n",
    "\n",
    "accuracy = test_results.filter(test_results.label == test_results.prediction).count() / float(test_results.count())\n",
    "roc_auc = evaluator.evaluate(test_results)\n",
    "print(\"Accuracy Score: {0:.4f}\".format(accuracy))\n",
    "print(\"ROC-AUC: {0:.4f}\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_results.select(['label']).collect()\n",
    "y_pred = test_results.select(['prediction']).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n         0.0       0.90      0.85      0.87     37559\n         1.0       0.69      0.78      0.73     16207\n\n    accuracy                           0.83     53766\n   macro avg       0.80      0.82      0.80     53766\nweighted avg       0.84      0.83      0.83     53766\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[31991  5568]\n [ 3573 12634]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+-----+\n|rating|count|\n+------+-----+\n|     1|37559|\n|     0|16207|\n+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "test_df.groupBy(\"rating\").count().orderBy(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigram_pipelineFit.save(\"binary_naive_bayes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}