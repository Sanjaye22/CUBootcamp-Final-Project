{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\Program Files\\Java\\jdk1.8.0_271\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"C:\\Installations\\Hadoop\"\n",
    "os.environ[\"SPARK_HOME\"] = \"D:\\spark-2.4.5-bin-hadoop2.7\\spark-2.4.5-bin-hadoop2.7\"\n",
    "\n",
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "    .appName(\"CloudETLProject\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd_test = pd.read_csv('../cleaned_nlp_data/testfinalmultirating.csv', sep=',')\n",
    "pd_train = pd.read_csv('../cleaned_nlp_data/trainfinalmultirating.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySchema = StructType([ StructField(\"uniqueID\", StringType(), True)\\\n",
    "                       ,StructField(\"drugName\", StringType(), True)\\\n",
    "                       ,StructField(\"condition\", StringType(), True)\\\n",
    "                       ,StructField(\"review\", StringType(), True)\\\n",
    "                       ,StructField(\"rating\", IntegerType(), True)\\\n",
    "                       ,StructField(\"date\", StringType(), True)\\\n",
    "                       ,StructField(\"usefulCount\", StringType(), True)\\\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkConf, SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "df_test = sqlContext.createDataFrame(pd_test, schema=mySchema)\n",
    "df_train = sqlContext.createDataFrame(pd_train, schema=mySchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_df = df_test.drop('uniqueID','drugName','condition', 'date', 'usefulCount' ).collect()\n",
    "drop_df_two = df_train.drop('uniqueID','drugName','condition', 'date', 'usefulCount' ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+------+\n|              review|rating|\n+--------------------+------+\n|gave me rapid hea...|     1|\n|    it cured my mrsa|     9|\n|i have been on zy...|     7|\n|it didnt work as ...|     6|\n|i have had  major...|     9|\n|i had mrsa inf la...|    10|\n|i got a mrsa stap...|     8|\n|very satisfied wi...|     9|\n|effectiveness las...|     4|\n|my psa was going ...|    10|\n|on zytiga for  mo...|    10|\n|began zytiga with...|    10|\n|had tried clariti...|     8|\n|this medicine wor...|    10|\n|i have had cholin...|     6|\n|after travelling ...|     9|\n|i suffered from m...|    10|\n|i recently had te...|     9|\n|it works great fo...|     9|\n|had hives nearly ...|    10|\n+--------------------+------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "test_df = spark.createDataFrame(drop_df)\n",
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+------+\n|              review|rating|\n+--------------------+------+\n|it has no side ef...|     9|\n|my son is halfway...|     8|\n|i used to take an...|     5|\n|this is my first ...|     8|\n|suboxone has comp...|     9|\n|nd day on mg star...|     2|\n|he pulled out but...|     1|\n|abilify changed m...|    10|\n| i ve had  nothin...|     1|\n|i had been on the...|     8|\n|i have been on th...|     9|\n|i have taken anti...|    10|\n|i had crohns with...|     4|\n|have a little bit...|     4|\n|started nexplanon...|     3|\n|i have been takin...|     9|\n|this drug worked ...|     9|\n|ive been taking a...|     9|\n|ive been on every...|    10|\n|i have been on ta...|    10|\n+--------------------+------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "train_df = spark.createDataFrame(drop_df_two)\n",
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trigrams(inputCol=[\"review\",\"rating\"], n=3):\n",
    "    tokenizer = [Tokenizer(inputCol=\"review\", outputCol=\"words\")]\n",
    "\n",
    "# Get rid of stop words\n",
    "    stopremove = [StopWordsRemover(inputCol='words',outputCol='stop_tokens')]\n",
    "\n",
    "# Stem the words\n",
    "\n",
    "# Creates a column for every word, two and three words. n=3\n",
    "    ngrams = [\n",
    "        NGram(n=i, inputCol=\"stop_tokens\", outputCol=\"{0}_grams\".format(i))\n",
    "        for i in range(1, n + 1)\n",
    "    ]\n",
    "# Min term frequency = how many times does it occur in review\n",
    "# df - times drug occurs in document \n",
    "    cv = [\n",
    "        CountVectorizer(vocabSize=2**15,inputCol=\"{0}_grams\".format(i),\n",
    "            outputCol=\"{0}_tf\".format(i))\n",
    "        for i in range(1, n + 1)\n",
    "    ]\n",
    "    idf = [IDF(inputCol=\"{0}_tf\".format(i), outputCol=\"{0}_tfidf\".format(i), minDocFreq=5) for i in range(1, n + 1)]\n",
    "# cv and idf act as a \n",
    "    assembler = [VectorAssembler(\n",
    "        inputCols=[\"{0}_tfidf\".format(i) for i in range(1, n + 1)],\n",
    "        outputCol=\"features\"\n",
    "    )]\n",
    "# stringindexer \n",
    "    label_stringIdx = [StringIndexer(inputCol = \"rating\", outputCol = \"label\")]\n",
    "    # selector = [ChiSqSelector(numTopFeatures=50,featuresCol='rawFeatures', outputCol=\"features\")]\n",
    "    lr = [LogisticRegression(maxIter=100)]\n",
    "    return Pipeline(stages=tokenizer + stopremove + ngrams + cv + idf + assembler + label_stringIdx + lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model \n",
    "trigram_pipelineFit = build_trigrams().fit(train_df)\n",
    "test_results = trigram_pipelineFit.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model Accuracy = 0.726314\n"
     ]
    }
   ],
   "source": [
    "# classification report - look for false positive, false negative. \n",
    "# use a different evaluator to try\n",
    "predictions = test_results.select(col(\"label\").cast(\"Float\"),col(\"prediction\"))\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Model Accuracy = %g\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "y_true = test_results.select(['label']).collect()\n",
    "y_pred = test_results.select(['prediction']).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n         0.0       0.79      0.81      0.80     17016\n         1.0       0.66      0.70      0.68      9177\n         2.0       0.79      0.79      0.79      7299\n         3.0       0.65      0.66      0.66      6156\n         4.0       0.66      0.62      0.64      3091\n         5.0       0.69      0.64      0.67      2710\n         6.0       0.72      0.66      0.69      2334\n         7.0       0.70      0.66      0.68      2205\n         8.0       0.70      0.61      0.65      2119\n         9.0       0.72      0.64      0.68      1659\n\n    accuracy                           0.73     53766\n   macro avg       0.71      0.68      0.69     53766\nweighted avg       0.73      0.73      0.73     53766\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[13791  1634   235   745   238    91    67    70    90    55]\n [ 1569  6398   121   587   200    94    48    44    84    32]\n [  327   200  5787   142    96   170   222   183    69   103]\n [  831   639   145  4070   169    83    38    51    93    37]\n [  338   272    90   227  1919    66    44    48    65    22]\n [  144   149   181   163   108  1743    49    57    58    58]\n [   92    81   309    58    38    53  1544    67    45    47]\n [   91    83   263    68    51    76    64  1449    27    33]\n [  162   169   107   128    63    79    33    59  1286    33]\n [   94    83   132    70    46    61    41    38    30  1064]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+-----+\n|rating|count|\n+------+-----+\n|    10|17016|\n|     9| 9177|\n|     1| 7299|\n|     8| 6156|\n|     7| 3091|\n|     5| 2710|\n|     2| 2334|\n|     3| 2205|\n|     6| 2119|\n|     4| 1659|\n+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "test_df.groupBy(\"rating\").count().orderBy(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testreview = spark.createDataFrame([\n",
    "                                    (\"Tylenol works, good product. I suffer from chronic migraines this combined with my other migraine cocktail works. Although I tried to order another bottle just now and I guess due to the corona virus 'covid 19' it's out of stock for awhile now, that's everywhere and those who are selling it are price gouging the prices $$$$$. It's aweful and disgraceful. This has to be tough for the hospitals too. Good product üëç\", 10)\n",
    "], [\"review\", \"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with a random review \n",
    "testreview = trigram_pipelineFit.transform(testreview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+\n|rawPrediction                                                                                                                                                                                |probability                                                                                                                                                                                                               |prediction|\n+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+\n|[28.429372410087034,-4.558546503825299,13.87719385375889,18.34385798846732,7.015806626280125,-38.16710367015818,-20.915407112480306,-5.599335003171681,14.34616590424422,-12.772004493202138]|[0.9999570785470678,4.715309514729229E-15,4.786857645572149E-7,4.16771582096599E-5,5.014041235422697E-10,1.1953615527290332E-29,3.7137776791754723E-22,1.6653345917973395E-15,7.651075473598307E-7,1.2777642208786596E-18]|0.0       |\n+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "testreview.select([\"rawPrediction\",\"probability\", \"prediction\"]).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model \n",
    "# trigram_pipelineFit.save(\"lr_multiclass\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}