{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\Program Files\\Java\\jdk1.8.0_271\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"C:\\Installations\\Hadoop\"\n",
    "os.environ[\"SPARK_HOME\"] = \"D:\\spark-2.4.5-bin-hadoop2.7\\spark-2.4.5-bin-hadoop2.7\"\n",
    "\n",
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "    .appName(\"CloudETLProject\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd_test = pd.read_csv('../cleaned_nlp_data/testfinalmultirating.csv', sep=',')\n",
    "pd_train = pd.read_csv('../cleaned_nlp_data/trainfinalmultirating.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySchema = StructType([ StructField(\"uniqueID\", StringType(), True)\\\n",
    "                       ,StructField(\"drugName\", StringType(), True)\\\n",
    "                       ,StructField(\"condition\", StringType(), True)\\\n",
    "                       ,StructField(\"review\", StringType(), True)\\\n",
    "                       ,StructField(\"rating\", IntegerType(), True)\\\n",
    "                       ,StructField(\"date\", StringType(), True)\\\n",
    "                       ,StructField(\"usefulCount\", StringType(), True)\\\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkConf, SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "df_test = sqlContext.createDataFrame(pd_test, schema=mySchema)\n",
    "df_train = sqlContext.createDataFrame(pd_train, schema=mySchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_df = df_test.drop('uniqueID','drugName','condition', 'date', 'usefulCount' ).collect()\n",
    "drop_df_two = df_train.drop('uniqueID','drugName','condition', 'date', 'usefulCount' ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+------+\n|              review|rating|\n+--------------------+------+\n|gave me rapid hea...|     1|\n|    it cured my mrsa|     9|\n|i have been on zy...|     7|\n|it didnt work as ...|     6|\n|i have had  major...|     9|\n|i had mrsa inf la...|    10|\n|i got a mrsa stap...|     8|\n|very satisfied wi...|     9|\n|effectiveness las...|     4|\n|my psa was going ...|    10|\n|on zytiga for  mo...|    10|\n|began zytiga with...|    10|\n|had tried clariti...|     8|\n|this medicine wor...|    10|\n|i have had cholin...|     6|\n|after travelling ...|     9|\n|i suffered from m...|    10|\n|i recently had te...|     9|\n|it works great fo...|     9|\n|had hives nearly ...|    10|\n+--------------------+------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "test_df = spark.createDataFrame(drop_df)\n",
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+------+\n|              review|rating|\n+--------------------+------+\n|it has no side ef...|     9|\n|my son is halfway...|     8|\n|i used to take an...|     5|\n|this is my first ...|     8|\n|suboxone has comp...|     9|\n|nd day on mg star...|     2|\n|he pulled out but...|     1|\n|abilify changed m...|    10|\n| i ve had  nothin...|     1|\n|i had been on the...|     8|\n|i have been on th...|     9|\n|i have taken anti...|    10|\n|i had crohns with...|     4|\n|have a little bit...|     4|\n|started nexplanon...|     3|\n|i have been takin...|     9|\n|this drug worked ...|     9|\n|ive been taking a...|     9|\n|ive been on every...|    10|\n|i have been on ta...|    10|\n+--------------------+------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "train_df = spark.createDataFrame(drop_df_two)\n",
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trigrams(inputCol=[\"review\",\"rating\"], n=3):\n",
    "    tokenizer = [Tokenizer(inputCol=\"review\", outputCol=\"words\")]\n",
    "\n",
    "# Get rid of stop words\n",
    "    stopremove = [StopWordsRemover(inputCol='words',outputCol='stop_tokens')]\n",
    "\n",
    "# Stem the words\n",
    "\n",
    "# Creates a column for every word, two and three words. n=3\n",
    "    ngrams = [\n",
    "        NGram(n=i, inputCol=\"stop_tokens\", outputCol=\"{0}_grams\".format(i))\n",
    "        for i in range(1, n + 1)\n",
    "    ]\n",
    "# Min term frequency = how many times does it occur in review\n",
    "# df - times drug occurs in document \n",
    "    cv = [\n",
    "        CountVectorizer(vocabSize=2**15,inputCol=\"{0}_grams\".format(i),\n",
    "            outputCol=\"{0}_tf\".format(i))\n",
    "        for i in range(1, n + 1)\n",
    "    ]\n",
    "    idf = [IDF(inputCol=\"{0}_tf\".format(i), outputCol=\"{0}_tfidf\".format(i), minDocFreq=5) for i in range(1, n + 1)]\n",
    "# cv and idf act as a \n",
    "    assembler = [VectorAssembler(\n",
    "        inputCols=[\"{0}_tfidf\".format(i) for i in range(1, n + 1)],\n",
    "        outputCol=\"features\"\n",
    "    )]\n",
    "# stringindexer \n",
    "    label_stringIdx = [StringIndexer(inputCol = \"rating\", outputCol = \"label\")]\n",
    "    # selector = [ChiSqSelector(numTopFeatures=50,featuresCol='rawFeatures', outputCol=\"features\")]\n",
    "    lr = [LogisticRegression(maxIter=100)]\n",
    "    return Pipeline(stages=tokenizer + stopremove + ngrams + cv + idf + assembler + label_stringIdx + lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model \n",
    "trigram_pipelineFit = build_trigrams().fit(train_df)\n",
    "test_results = trigram_pipelineFit.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model Accuracy = 0.7257\n"
     ]
    }
   ],
   "source": [
    "# classification report - look for false positive, false negative. \n",
    "# use a different evaluator to try\n",
    "predictions = test_results.select(col(\"label\").cast(\"Float\"),col(\"prediction\"))\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Model Accuracy = %g\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_pipelineFit.save(\"lr_multiclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|rating|count|\n",
      "+------+-----+\n",
      "|    10|50989|\n",
      "|     9|27531|\n",
      "|     1|21619|\n",
      "|     8|18890|\n",
      "|     7| 9456|\n",
      "|     5| 8013|\n",
      "|     2| 6931|\n",
      "|     3| 6513|\n",
      "|     6| 6343|\n",
      "|     4| 5012|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.groupBy(\"rating\").count().orderBy(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}